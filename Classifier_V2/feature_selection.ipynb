{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import csv\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import antropy as ant\n",
    "from sklearn.feature_selection import SelectFdr, SelectPercentile, SelectKBest, chi2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin, end = 1, 61 # (begin is inclusive, end is exclusive)\n",
    "num_people = 14\n",
    "count_samples = {\n",
    "    \"active\": 8,\n",
    "    \"meditate\": 8,\n",
    "    \"neutral\": 8\n",
    "}\n",
    "\n",
    "class Sample:\n",
    "    def __init__(self):\n",
    "        self.data = {\n",
    "            'RawEEG': [],\n",
    "            'Alpha': [],\n",
    "            'Low Beta': [],\n",
    "            'High Beta': [],\n",
    "            'Gamma': [],\n",
    "            'Theta': [],\n",
    "            'Delta': [],\n",
    "            'Meditation': [],\n",
    "            'Attention': []\n",
    "        }\n",
    "\n",
    "    def recordDataPoint(self, RawEEG, Attention, Meditation, Alpha, Delta, Theta, LowBeta, HighBeta, Gamma):\n",
    "        self.data['RawEEG'].append(float(RawEEG))\n",
    "        self.data['Attention'].append(float(Attention))\n",
    "        self.data['Meditation'].append(float(Meditation))\n",
    "        self.data['Alpha'].append(float(Alpha))\n",
    "        self.data['Delta'].append(float(Delta))\n",
    "        self.data['Theta'].append(float(Theta))\n",
    "        self.data['Low Beta'].append(float(LowBeta))\n",
    "        self.data['High Beta'].append(float(HighBeta))\n",
    "        self.data['Gamma'].append(float(Gamma))\n",
    "\n",
    "    '''\n",
    "    Record a line of data from the CSV output, which takes form RawEEG, Alpha, Delta, Gamma, Low Beta, High Beta, Theta, Attention, Meditation\n",
    "\n",
    "    '''\n",
    "    def recordDataLine(self, line):\n",
    "        self.recordDataPoint(line[0], line[7], line[8], line[1], line[2], line[6], line[4], line[5], line[3])\n",
    "    \n",
    "    def getEEG(self):\n",
    "        return self.data['RawEEG']\n",
    "    \n",
    "    def getAttention(self):\n",
    "        return self.data[\"Attention\"]\n",
    "    \n",
    "    def getMeditation(self):\n",
    "        return self.data[\"Meditation\"]\n",
    "    \n",
    "    def getAlpha(self):\n",
    "        return self.data[\"Alpha\"]\n",
    "    \n",
    "    def getDelta(self):\n",
    "        return self.data[\"Delta\"]\n",
    "    \n",
    "    def getTheta(self):\n",
    "        return self.data[\"Theta\"]\n",
    "    \n",
    "    def getLowBeta(self):\n",
    "        return self.data[\"Low Beta\"]\n",
    "    \n",
    "    def getHighBeta(self):\n",
    "        return self.data[\"High Beta\"]\n",
    "    \n",
    "    def getGamma(self):\n",
    "        return self.data[\"Gamma\"]\n",
    "\n",
    "    def get(self, key):\n",
    "        return self.data[key]\n",
    "\n",
    "    '''\n",
    "    Filter out all outliers, as defined by being outside 3*std from the mean, and replace with mean of the samples around them\n",
    "    '''\n",
    "    def filter_outliers(self):\n",
    "        sampleBad = False\n",
    "        for key in ['RawEEG', 'Alpha', 'Theta', 'Low Beta', 'High Beta', \"Gamma\", 'Delta']:\n",
    "            data = self.data[key]\n",
    "            \n",
    "            filtered = []\n",
    "            for i, x in enumerate(data):\n",
    "                iqr = np.subtract(*np.percentile(data, [75, 25]))\n",
    "                med = np.median(data)\n",
    "                if (med - 1.5*iqr > x) or (med + 1.5*iqr < x) or abs(x - np.mean(data)) > 2 * np.std(data):\n",
    "                    filtered.append(med)\n",
    "                    # filtered.append(np.median(data[max(0, i-5):i] + data[i+1:min(len(data), i+5)]))\n",
    "                else:\n",
    "                    filtered.append(x)\n",
    "                    \n",
    "            self.data[key] = filtered\n",
    "        return sampleBad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {personNum : {state: [sampleNums]}}\n",
    "# 0 = key for throwing away all samples of that state\n",
    "\n",
    "badSamples = {\n",
    "    1: {\"active\": [5], \"neutral\": [2], \"meditate\": []},\n",
    "    2: {\"active\": [0], \"neutral\": [0], \"meditate\": [0]},\n",
    "    3: {\"active\": [1, 4], \"neutral\": [1], \"meditate\": [5, 6, 7, 8]},\n",
    "    4: {\"active\": [2], \"neutral\": [7], \"meditate\": [1, 8]}, # maybe n1\n",
    "    5: {\"active\": [], \"neutral\": [], \"meditate\": []}, # i love you person 5 \n",
    "    6: {\"active\": [], \"neutral\": [2, 6], \"meditate\": []},\n",
    "    7: {\"active\": [5], \"neutral\": [4, 6, 7], \"meditate\": [1, 3, 4, 8]}, # think about killing some of this data\n",
    "    8: {\"active\": [5], \"neutral\": [1], \"meditate\": []}, # maybe m5 and m8\n",
    "    9: {\"active\": [], \"neutral\": [], \"meditate\": []}, \n",
    "    10: {\"active\": [6, 8], \"neutral\": [4, 5, 6], \"meditate\": []},\n",
    "    11: {\"active\": [4], \"neutral\": [4, 8], \"meditate\": [1, 2, 3, 5, 7]},\n",
    "    12: {\"active\": [2, 3, 8], \"neutral\": [0], \"meditate\": [6]}, # maybe n0\n",
    "    13: {\"active\": [], \"neutral\": [8], \"meditate\": []},\n",
    "    14: {\"active\": [4, 5, 8], \"neutral\": [0], \"meditate\": [1, 2, 8]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "dataLabels = []\n",
    "\n",
    "def transcribeFileToSample(personN: int, sampleN: int, state: str):\n",
    "    sample_data = Sample()\n",
    "\n",
    "    with open(\"data/all_data/\" + state + \"_\" + str(personN) + \"_\" + str(sampleN) + \".csv\") as f:\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "        header = next(reader)\n",
    "        \n",
    "        for row in reader:\n",
    "            sample_data.recordDataLine(row)\n",
    "            \n",
    "        if (0 not in badSamples[personN][state] and sampleN not in badSamples[personN][state]):\n",
    "\n",
    "            for key in sample_data.data:\n",
    "                sample_data.data[key] = sample_data.data[key][begin:end]\n",
    "\n",
    "            sample_data.filter_outliers()\n",
    "            data.append(sample_data)\n",
    "            dataLabels.append(state)\n",
    "\n",
    "for person in range(num_people):\n",
    "    for state in count_samples:\n",
    "        for i in range(count_samples[state]):\n",
    "            transcribeFileToSample(person + 1, i + 1, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/antropy/entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/antropy/entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    }
   ],
   "source": [
    "dataExtracted = []\n",
    "\n",
    "def safety_check(x):\n",
    "    if math.isnan(x): return 0\n",
    "    if math.isinf(x): return 99999999999\n",
    "    return x\n",
    "\n",
    "for point in data:\n",
    "    extractedPoint = []\n",
    "\n",
    "    for key in point.data:\n",
    "        if key == 'Meditation' or key == 'Attention': continue\n",
    "        for func in [np.mean, np.std, ant.sample_entropy, ant.higuchi_fd]:\n",
    "            extractedPoint.append(safety_check(func(point.get(key))))\n",
    "\n",
    "    extractedPoint.append(safety_check(ant.spectral_entropy(point.getEEG(), sf=1)))\n",
    "    \n",
    "    dataExtracted.append(extractedPoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataExtracted.copy()\n",
    "y = dataLabels.copy()\n",
    "feature_names = []\n",
    "bands = ['Raw EEG', 'Alpha', 'Low Beta', 'High Beta', 'Gamma', 'Theta', 'Delta']\n",
    "for band in bands:\n",
    "    feature_names.append(\"mean \" + band)\n",
    "    feature_names.append(\"std \" + band)\n",
    "    feature_names.append(\"sample entropy \" + band)\n",
    "    feature_names.append(\"higuchi fd \" + band)\n",
    "feature_names.append(\"spectral entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean Low Beta', 'mean High Beta', 'std High Beta', 'mean Gamma',\n",
       "       'std Gamma'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentile = SelectKBest(k=5)\n",
    "X_new = percentile.fit_transform(X, y)\n",
    "percentile.get_feature_names_out(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std Gamma 0.08092091215971141\n",
      "mean Theta 0.07414497719509928\n",
      "mean Gamma 0.06991423535926411\n",
      "mean High Beta 0.06009976707123903\n",
      "std High Beta 0.05394636983455957\n",
      "std Theta 0.04820730060929454\n",
      "mean Low Beta 0.046156882504495955\n",
      "std Delta 0.043713862780865226\n",
      "mean Alpha 0.039576546560637076\n",
      "mean Delta 0.035673375716230256\n",
      "std Low Beta 0.03562598938599488\n",
      "sample entropy Delta 0.03232278362972651\n",
      "std Raw EEG 0.029204513086664795\n",
      "higuchi fd Gamma 0.028663091528539734\n",
      "std Alpha 0.023891149935124405\n",
      "sample entropy Low Beta 0.02362338017327561\n",
      "higuchi fd Alpha 0.023482040674867886\n",
      "higuchi fd Low Beta 0.02265263664387047\n",
      "sample entropy High Beta 0.02204225775246362\n",
      "higuchi fd Delta 0.021789294600848\n",
      "sample entropy Alpha 0.021578207765799592\n",
      "spectral entropy 0.02157277456645085\n",
      "higuchi fd High Beta 0.021322295593403724\n",
      "sample entropy Raw EEG 0.020935850323483586\n",
      "higuchi fd Theta 0.020892955686202804\n",
      "sample entropy Gamma 0.020492509526418762\n",
      "mean Raw EEG 0.019905093844658196\n",
      "sample entropy Theta 0.0188394351266676\n",
      "higuchi fd Raw EEG 0.01880951036414253\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=1800, max_depth=70, random_state=0)\n",
    "forest.fit(X, y)\n",
    "\n",
    "for name, importance in sorted(zip(feature_names, forest.feature_importances_), key=lambda x: x[1], reverse=True):\n",
    "    print(name, importance)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
  },
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
