{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import csv\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import antropy as ant\n",
    "from sklearn.feature_selection import SelectFdr, SelectPercentile, SelectKBest, chi2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin, end = 1, 61 # (begin is inclusive, end is exclusive)\n",
    "num_people = 14\n",
    "count_samples = {\n",
    "    \"active\": 8,\n",
    "    \"meditate\": 8,\n",
    "    \"neutral\": 8\n",
    "}\n",
    "\n",
    "class Sample:\n",
    "    def __init__(self):\n",
    "        self.data = {\n",
    "            'RawEEG': [],\n",
    "            'Alpha': [],\n",
    "            'Low Beta': [],\n",
    "            'High Beta': [],\n",
    "            'Gamma': [],\n",
    "            'Theta': [],\n",
    "            'Delta': [],\n",
    "            'Meditation': [],\n",
    "            'Attention': []\n",
    "        }\n",
    "\n",
    "    def recordDataPoint(self, RawEEG, Attention, Meditation, Alpha, Delta, Theta, LowBeta, HighBeta, Gamma):\n",
    "        self.data['RawEEG'].append(float(RawEEG))\n",
    "        self.data['Attention'].append(float(Attention))\n",
    "        self.data['Meditation'].append(float(Meditation))\n",
    "        self.data['Alpha'].append(float(Alpha))\n",
    "        self.data['Delta'].append(float(Delta))\n",
    "        self.data['Theta'].append(float(Theta))\n",
    "        self.data['Low Beta'].append(float(LowBeta))\n",
    "        self.data['High Beta'].append(float(HighBeta))\n",
    "        self.data['Gamma'].append(float(Gamma))\n",
    "\n",
    "    '''\n",
    "    Record a line of data from the CSV output, which takes form RawEEG, Alpha, Delta, Gamma, Low Beta, High Beta, Theta, Attention, Meditation\n",
    "\n",
    "    '''\n",
    "    def recordDataLine(self, line):\n",
    "        self.recordDataPoint(line[0], line[7], line[8], line[1], line[2], line[6], line[4], line[5], line[3])\n",
    "    \n",
    "    def getEEG(self):\n",
    "        return self.data['RawEEG']\n",
    "    \n",
    "    def getAttention(self):\n",
    "        return self.data[\"Attention\"]\n",
    "    \n",
    "    def getMeditation(self):\n",
    "        return self.data[\"Meditation\"]\n",
    "    \n",
    "    def getAlpha(self):\n",
    "        return self.data[\"Alpha\"]\n",
    "    \n",
    "    def getDelta(self):\n",
    "        return self.data[\"Delta\"]\n",
    "    \n",
    "    def getTheta(self):\n",
    "        return self.data[\"Theta\"]\n",
    "    \n",
    "    def getLowBeta(self):\n",
    "        return self.data[\"Low Beta\"]\n",
    "    \n",
    "    def getHighBeta(self):\n",
    "        return self.data[\"High Beta\"]\n",
    "    \n",
    "    def getGamma(self):\n",
    "        return self.data[\"Gamma\"]\n",
    "\n",
    "    def get(self, key):\n",
    "        return self.data[key]\n",
    "\n",
    "    '''\n",
    "    Filter out all outliers, as defined by being outside 3*std from the mean, and replace with mean of the samples around them\n",
    "    '''\n",
    "    def filter_outliers(self):\n",
    "        sampleBad = False\n",
    "        for key in ['RawEEG', 'Alpha', 'Theta', 'Low Beta', 'High Beta', \"Gamma\", 'Delta']:\n",
    "            data = self.data[key]\n",
    "            \n",
    "            filtered = []\n",
    "            for i, x in enumerate(data):\n",
    "                iqr = np.subtract(*np.percentile(data, [75, 25]))\n",
    "                med = np.median(data)\n",
    "                if (med - 1.5*iqr > x) or (med + 1.5*iqr < x) or abs(x - np.mean(data)) > 2 * np.std(data):\n",
    "                    filtered.append(med)\n",
    "                    # filtered.append(np.median(data[max(0, i-5):i] + data[i+1:min(len(data), i+5)]))\n",
    "                else:\n",
    "                    filtered.append(x)\n",
    "                    \n",
    "            self.data[key] = filtered\n",
    "        return sampleBad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {personNum : {state: [sampleNums]}}\n",
    "# 0 = key for throwing away all samples of that state\n",
    "\n",
    "badSamples = {\n",
    "    1: {\"active\": [5], \"neutral\": [2], \"meditate\": []},\n",
    "    2: {\"active\": [0], \"neutral\": [0], \"meditate\": [0]},\n",
    "    3: {\"active\": [1, 4], \"neutral\": [1], \"meditate\": [5, 6, 7, 8]},\n",
    "    4: {\"active\": [2], \"neutral\": [7], \"meditate\": [1, 8]}, # maybe n1\n",
    "    5: {\"active\": [], \"neutral\": [], \"meditate\": []}, # i love you person 5 \n",
    "    6: {\"active\": [], \"neutral\": [2, 6], \"meditate\": []},\n",
    "    7: {\"active\": [5], \"neutral\": [4, 6, 7], \"meditate\": [1, 3, 4, 8]}, # think about killing some of this data\n",
    "    8: {\"active\": [5], \"neutral\": [1], \"meditate\": []}, # maybe m5 and m8\n",
    "    9: {\"active\": [], \"neutral\": [], \"meditate\": []}, \n",
    "    10: {\"active\": [6, 8], \"neutral\": [4, 5, 6], \"meditate\": []},\n",
    "    11: {\"active\": [4], \"neutral\": [4, 8], \"meditate\": [1, 2, 3, 5, 7]},\n",
    "    12: {\"active\": [2, 3, 8], \"neutral\": [0], \"meditate\": [6]}, # maybe n0\n",
    "    13: {\"active\": [], \"neutral\": [8], \"meditate\": []},\n",
    "    14: {\"active\": [4, 5, 8], \"neutral\": [0], \"meditate\": [1, 2, 8]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "dataLabels = []\n",
    "\n",
    "def transcribeFileToSample(personN: int, sampleN: int, state: str):\n",
    "    sample_data = Sample()\n",
    "\n",
    "    with open(\"data/all_data/\" + state + \"_\" + str(personN) + \"_\" + str(sampleN) + \".csv\") as f:\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "        header = next(reader)\n",
    "        \n",
    "        for row in reader:\n",
    "            sample_data.recordDataLine(row)\n",
    "            \n",
    "        if (0 not in badSamples[personN][state] and sampleN not in badSamples[personN][state]):\n",
    "\n",
    "            for key in sample_data.data:\n",
    "                sample_data.data[key] = sample_data.data[key][begin:end]\n",
    "\n",
    "            sample_data.filter_outliers()\n",
    "            data.append(sample_data)\n",
    "            dataLabels.append(state)\n",
    "\n",
    "for person in range(num_people):\n",
    "    for state in count_samples:\n",
    "        for i in range(count_samples[state]):\n",
    "            transcribeFileToSample(person + 1, i + 1, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\antropy\\entropy.py:249: RuntimeWarning: divide by zero encountered in log2\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n",
      "C:\\Users\\mikad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\antropy\\entropy.py:249: RuntimeWarning: invalid value encountered in multiply\n",
      "  se = -(psd_norm * np.log2(psd_norm)).sum(axis=axis)\n"
     ]
    }
   ],
   "source": [
    "dataExtracted = []\n",
    "\n",
    "def safety_check(x):\n",
    "    if math.isnan(x): return 0\n",
    "    if math.isinf(x): return 99999999999\n",
    "    return x\n",
    "\n",
    "for point in data:\n",
    "    extractedPoint = []\n",
    "\n",
    "    for key in point.data:\n",
    "        if key == 'RawEEG' or key == 'Meditation' or key == 'Attention': continue\n",
    "        for func in [np.mean, np.std, ant.sample_entropy, ant.petrosian_fd]:\n",
    "            extractedPoint.append(safety_check(func(point.get(key))))\n",
    "\n",
    "    extractedPoint.append(safety_check(ant.spectral_entropy(point.getEEG(), sf=1)))\n",
    "    \n",
    "    dataExtracted.append(extractedPoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sample entropy High Beta'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataExtracted.copy()\n",
    "y = dataLabels.copy()\n",
    "feature_names = []\n",
    "bands = ['Alpha', 'Low Beta', 'High Beta', 'Gamma', 'Theta', 'Delta']\n",
    "for band in bands:\n",
    "    feature_names.append(\"mean \" + band)\n",
    "    feature_names.append(\"std \" + band)\n",
    "    feature_names.append(\"sample entropy \" + band)\n",
    "    feature_names.append(\"petrosian fd \" + band)\n",
    "feature_names.append(\"spectal entropy\")\n",
    "percentile = SelectKBest(chi2, k=1)\n",
    "X_new = percentile.fit_transform(X, y)\n",
    "percentile.get_feature_names_out(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean Alpha 0.03476809090784033\n",
      "std Alpha 0.028218762076033254\n",
      "sample entropy Alpha 0.026148812116149625\n",
      "petrosian fd Alpha 0.01923465262599053\n",
      "mean Low Beta 0.05026599002537205\n",
      "std Low Beta 0.038785805953119354\n",
      "sample entropy Low Beta 0.025528068390750544\n",
      "petrosian fd Low Beta 0.022894963118998107\n",
      "mean High Beta 0.06778958694541182\n",
      "std High Beta 0.07281027958450406\n",
      "sample entropy High Beta 0.02439117432565899\n",
      "petrosian fd High Beta 0.01600969344214077\n",
      "mean Gamma 0.0825852500847713\n",
      "std Gamma 0.09386470288526677\n",
      "sample entropy Gamma 0.023776859873572188\n",
      "petrosian fd Gamma 0.024894408765733785\n",
      "mean Theta 0.0672575930011168\n",
      "std Theta 0.04745956751659164\n",
      "sample entropy Theta 0.025847780564929354\n",
      "petrosian fd Theta 0.030968357463410215\n",
      "mean Delta 0.04243862471461758\n",
      "std Delta 0.04915445415442107\n",
      "sample entropy Delta 0.03506598040517744\n",
      "petrosian fd Delta 0.020356075274980623\n",
      "spectal entropy 0.02948446578344177\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
  },
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
