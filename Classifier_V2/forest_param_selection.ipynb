{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin, end = 1, 61 # (begin is inclusive, end is exclusive)\n",
    "num_people = 14\n",
    "count_samples = {\n",
    "    \"active\": 8,\n",
    "    \"meditate\": 8,\n",
    "    \"neutral\": 8\n",
    "}\n",
    "\n",
    "class Sample:\n",
    "    def __init__(self):\n",
    "        self.data = {\n",
    "            'RawEEG': [],\n",
    "            'Alpha': [],\n",
    "            'Low Beta': [],\n",
    "            'High Beta': [],\n",
    "            'Gamma': [],\n",
    "            'Theta': [],\n",
    "            'Delta': [],\n",
    "            'Meditation': [],\n",
    "            'Attention': []\n",
    "        }\n",
    "\n",
    "    def recordDataPoint(self, RawEEG, Attention, Meditation, Alpha, Delta, Theta, LowBeta, HighBeta, Gamma):\n",
    "        self.data['RawEEG'].append(float(RawEEG))\n",
    "        self.data['Attention'].append(float(Attention))\n",
    "        self.data['Meditation'].append(float(Meditation))\n",
    "        self.data['Alpha'].append(float(Alpha))\n",
    "        self.data['Delta'].append(float(Delta))\n",
    "        self.data['Theta'].append(float(Theta))\n",
    "        self.data['Low Beta'].append(float(LowBeta))\n",
    "        self.data['High Beta'].append(float(HighBeta))\n",
    "        self.data['Gamma'].append(float(Gamma))\n",
    "\n",
    "    '''\n",
    "    Record a line of data from the CSV output, which takes form RawEEG, Alpha, Delta, Gamma, Low Beta, High Beta, Theta, Attention, Meditation\n",
    "\n",
    "    '''\n",
    "    def recordDataLine(self, line):\n",
    "        self.recordDataPoint(line[0], line[7], line[8], line[1], line[2], line[6], line[4], line[5], line[3])\n",
    "    \n",
    "    def getEEG(self):\n",
    "        return self.data['RawEEG']\n",
    "    \n",
    "    def getAttention(self):\n",
    "        return self.data[\"Attention\"]\n",
    "    \n",
    "    def getMeditation(self):\n",
    "        return self.data[\"Meditation\"]\n",
    "    \n",
    "    def getAlpha(self):\n",
    "        return self.data[\"Alpha\"]\n",
    "    \n",
    "    def getDelta(self):\n",
    "        return self.data[\"Delta\"]\n",
    "    \n",
    "    def getTheta(self):\n",
    "        return self.data[\"Theta\"]\n",
    "    \n",
    "    def getLowBeta(self):\n",
    "        return self.data[\"Low Beta\"]\n",
    "    \n",
    "    def getHighBeta(self):\n",
    "        return self.data[\"High Beta\"]\n",
    "    \n",
    "    def getGamma(self):\n",
    "        return self.data[\"Gamma\"]\n",
    "\n",
    "    def get(self, key):\n",
    "        return self.data[key]\n",
    "\n",
    "    '''\n",
    "    Filter out all outliers, as defined by being outside 3*std from the mean, and replace with mean of the samples around them\n",
    "    '''\n",
    "    def filter_outliers(self):\n",
    "        sampleBad = False\n",
    "        for key in ['RawEEG', 'Alpha', 'Theta', 'Low Beta', 'High Beta', \"Gamma\", 'Delta']:\n",
    "            data = self.data[key]\n",
    "            \n",
    "            filtered = []\n",
    "            for i, x in enumerate(data):\n",
    "                if (key != \"RawEEG\" and (x > 0.8)):\n",
    "                    sampleBad = True\n",
    "                    break\n",
    "                elif abs(x - np.median(data)) < 2 * np.std(data):\n",
    "                    filtered.append(x)\n",
    "                else:\n",
    "                    filtered.append(np.median(data[max(0, i-5):i] + data[i+1:min(len(data), i+5)])) # Mean of the four values in closest time to the outlier, but avoiding index out of bounds\n",
    "                    # filtered.append(np.median(data))\n",
    "                    \n",
    "            self.data[key] = filtered\n",
    "        return sampleBad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {personNum : {state: [sampleNums]}}\n",
    "# 0 = key for throwing away all samples of that state\n",
    "\n",
    "badSamples = {\n",
    "    1: {\"active\": [5], \"neutral\": [2], \"meditate\": []},\n",
    "    2: {\"active\": [0], \"neutral\": [0], \"meditate\": [0]},\n",
    "    3: {\"active\": [1, 4], \"neutral\": [1], \"meditate\": [5, 6, 7, 8]},\n",
    "    4: {\"active\": [2], \"neutral\": [7], \"meditate\": [1, 8]}, # maybe n1\n",
    "    5: {\"active\": [], \"neutral\": [], \"meditate\": []}, # i love you person 5 \n",
    "    6: {\"active\": [], \"neutral\": [2, 6], \"meditate\": []},\n",
    "    7: {\"active\": [5], \"neutral\": [4, 6, 7], \"meditate\": [1, 3, 4, 8]}, # think about killing some of this data\n",
    "    8: {\"active\": [5], \"neutral\": [1], \"meditate\": []}, # maybe m5 and m8\n",
    "    9: {\"active\": [], \"neutral\": [], \"meditate\": []}, \n",
    "    10: {\"active\": [6, 8], \"neutral\": [4, 5, 6], \"meditate\": []},\n",
    "    11: {\"active\": [4], \"neutral\": [4, 8], \"meditate\": [1, 2, 3, 5, 7]},\n",
    "    12: {\"active\": [2, 3, 8], \"neutral\": [0], \"meditate\": [6]}, # maybe n0\n",
    "    13: {\"active\": [], \"neutral\": [8], \"meditate\": []},\n",
    "    14: {\"active\": [4, 5, 8], \"neutral\": [0], \"meditate\": [1, 2, 8]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "dataLabels = []\n",
    "\n",
    "def transcribeFileToSample(personN: int, sampleN: int, state: str):\n",
    "    sample_data = Sample()\n",
    "\n",
    "    with open(\"data/all_data/\" + state + \"_\" + str(personN) + \"_\" + str(sampleN) + \".csv\") as f:\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "        header = next(reader)\n",
    "        \n",
    "        for row in reader:\n",
    "            sample_data.recordDataLine(row)\n",
    "            \n",
    "        if (0 not in badSamples[personN][state] and sampleN not in badSamples[personN][state]):\n",
    "\n",
    "            for key in sample_data.data:\n",
    "                sample_data.data[key] = sample_data.data[key][begin:end]\n",
    "\n",
    "            sampleBad = sample_data.filter_outliers()\n",
    "\n",
    "            if (not sampleBad):   \n",
    "                # sample_data.filter_outliers()\n",
    "                data.append(sample_data)\n",
    "                dataLabels.append(state)\n",
    "\n",
    "for person in range(num_people):\n",
    "    for state in count_samples:\n",
    "        for i in range(count_samples[state]):\n",
    "            transcribeFileToSample(person + 1, i + 1, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataExtracted = []\n",
    "\n",
    "for point in data:\n",
    "    extractedPoint = []\n",
    "\n",
    "    extractedPoint.append(np.mean(point.getAlpha()))\n",
    "    extractedPoint.append(np.mean(point.getLowBeta()))\n",
    "    extractedPoint.append(np.std(point.getAlpha()))\n",
    "    extractedPoint.append(np.mean(point.getTheta()))\n",
    "    extractedPoint.append(np.std(point.getGamma()))\n",
    "    extractedPoint.append(np.std(point.getDelta()))\n",
    "\n",
    "    dataExtracted.append(extractedPoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "train, test, trainLabels, testLabels = train_test_split(dataExtracted, dataLabels, test_size=0.20)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "rf_random.fit(train, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1200,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 20,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True],\n",
       "                         'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100,\n",
       "                                       110, None],\n",
       "                         'max_features': ['auto', 'sqrt'],\n",
       "                         'min_samples_leaf': [1, 2],\n",
       "                         'min_samples_split': [2, 5],\n",
       "                         'n_estimators': [1000, 1200, 1400]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'bootstrap': [True], \n",
    "    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
    "    'max_features': ['auto', 'sqrt'], \n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'min_samples_split': [2, 5], \n",
    "    'n_estimators': [1000, 1200, 1400]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(train, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 70,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=70, n_estimators=1000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "best_grid"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cb6d1e253a7ab3e8a07d0a3da00ac1f2b77bfa839ee5db5b3eaf4eb76ff3570"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
