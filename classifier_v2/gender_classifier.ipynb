{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import antropy as ant\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"active\", \"meditate\", \"neutral\"]\n",
    "n_samples_per_state = 8\n",
    "\n",
    "labels = {\n",
    "    1: \"Female\",\n",
    "    2: \"Male\",\n",
    "    3: \"Male\",\n",
    "    4: \"Male\",\n",
    "    5: \"Female\",\n",
    "    6: \"Female\",\n",
    "    7: \"Female\",\n",
    "    8: \"Male\",\n",
    "    9: \"Male\",\n",
    "    10: \"Male\",\n",
    "    11: \"Female\",\n",
    "    12: \"Male\",\n",
    "    13: \"Male\",\n",
    "    14: \"Male\",\n",
    "}\n",
    "\n",
    "class Sample:\n",
    "    def __init__(self):\n",
    "        self.data = {\n",
    "            'RawEEG': [],\n",
    "            'Alpha': [],\n",
    "            'Low Beta': [],\n",
    "            'High Beta': [],\n",
    "            'Gamma': [],\n",
    "            'Theta': [],\n",
    "            'Delta': [],\n",
    "            'Meditation': [],\n",
    "            'Attention': []\n",
    "        }\n",
    "\n",
    "    def recordDataPoint(self, RawEEG, Attention, Meditation, Alpha, Delta, Theta, LowBeta, HighBeta, Gamma):\n",
    "        self.data['RawEEG'].append(float(RawEEG))\n",
    "        self.data['Attention'].append(float(Attention))\n",
    "        self.data['Meditation'].append(float(Meditation))\n",
    "        self.data['Alpha'].append(float(Alpha))\n",
    "        self.data['Delta'].append(float(Delta))\n",
    "        self.data['Theta'].append(float(Theta))\n",
    "        self.data['Low Beta'].append(float(LowBeta))\n",
    "        self.data['High Beta'].append(float(HighBeta))\n",
    "        self.data['Gamma'].append(float(Gamma))\n",
    "\n",
    "    '''\n",
    "    Record a line of data from the CSV output, which takes form RawEEG, Alpha, Delta, Gamma, Low Beta, High Beta, Theta, Attention, Meditation\n",
    "\n",
    "    '''\n",
    "    def recordDataLine(self, line):\n",
    "        self.recordDataPoint(line[0], line[7], line[8], line[1], line[2], line[6], line[4], line[5], line[3])\n",
    "    \n",
    "    def getEEG(self):\n",
    "        return self.data['RawEEG']\n",
    "    \n",
    "    def getAttention(self):\n",
    "        return self.data[\"Attention\"]\n",
    "    \n",
    "    def getMeditation(self):\n",
    "        return self.data[\"Meditation\"]\n",
    "    \n",
    "    def getAlpha(self):\n",
    "        return self.data[\"Alpha\"]\n",
    "    \n",
    "    def getDelta(self):\n",
    "        return self.data[\"Delta\"]\n",
    "    \n",
    "    def getTheta(self):\n",
    "        return self.data[\"Theta\"]\n",
    "    \n",
    "    def getLowBeta(self):\n",
    "        return self.data[\"Low Beta\"]\n",
    "    \n",
    "    def getHighBeta(self):\n",
    "        return self.data[\"High Beta\"]\n",
    "    \n",
    "    def getGamma(self):\n",
    "        return self.data[\"Gamma\"]\n",
    "\n",
    "    def get(self, key):\n",
    "        return self.data[key]\n",
    "\n",
    "    '''\n",
    "    Filter out all outliers, as defined by being outside 3*std from the mean, and replace with mean of the samples around them\n",
    "    '''\n",
    "    def filter_outliers(self):\n",
    "        for key in self.data:\n",
    "            data = self.data[key]\n",
    "            \n",
    "            filtered = []\n",
    "            for i, x in enumerate(data):\n",
    "                if abs(x - np.mean(data)) < 3 * np.std(data):\n",
    "                    filtered.append(x)\n",
    "                else:\n",
    "                    filtered.append(np.mean(data[max(0, i-2):i] + data[i+1:min(len(data), i+2)]))\n",
    "            self.data[key] = filtered\n",
    "\n",
    "            # self.data[key] = [x for x in self.data[key] if abs(x - np.mean(self.data[key])) < 3 * np.std(self.data[key])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "dataLabels = []\n",
    "\n",
    "def transcribeFileToSample(personN: int, sampleN: int, state: str):\n",
    "    sample_data = Sample()\n",
    "\n",
    "    with open(f\"data/all_data/{state}_{personN}_{sampleN}.csv\") as f:\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "        header = next(reader)\n",
    "        \n",
    "        for row in reader:\n",
    "            sample_data.recordDataLine(row)\n",
    "\n",
    "        sample_data.filter_outliers()\n",
    "\n",
    "        data.append(sample_data)\n",
    "        dataLabels.append(labels[personN])\n",
    "\n",
    "for person in labels:\n",
    "    for state in states:\n",
    "        for i in range(n_samples_per_state):\n",
    "            transcribeFileToSample(person, i + 1, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataExtracted = []\n",
    "\n",
    "def safety_check(x):\n",
    "    if math.isnan(x): return 0\n",
    "    if math.isinf(x): return 99999999999\n",
    "    return x\n",
    "\n",
    "for point in data:\n",
    "    extractedPoint = []\n",
    "\n",
    "    extractedPoint.append(np.std(point.getGamma()))\n",
    "    extractedPoint.append(np.mean(point.getTheta()))\n",
    "    extractedPoint.append(np.mean(point.getGamma()))\n",
    "    extractedPoint.append(np.mean(point.getHighBeta()))\n",
    "    extractedPoint.append(np.std(point.getHighBeta()))\n",
    "    extractedPoint.append(np.std(point.getTheta()))\n",
    "    extractedPoint.append(np.mean(point.getLowBeta()))\n",
    "    extractedPoint.append(np.std(point.getDelta()))\n",
    "    extractedPoint.append(np.mean(point.getAlpha()))\n",
    "    extractedPoint.append(np.mean(point.getDelta()))\n",
    "    extractedPoint.append(np.std(point.getLowBeta()))\n",
    "    extractedPoint.append(safety_check(ant.sample_entropy(point.getDelta())))\n",
    "\n",
    "    dataExtracted.append(extractedPoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84 accuracy with a standard deviation of 0.09\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cvclf = make_pipeline(StandardScaler(), RandomForestClassifier(max_depth=20, n_estimators=2000))\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "scores = cross_val_score(cvclf, dataExtracted, dataLabels, cv=cv)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
  },
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
