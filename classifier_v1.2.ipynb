{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the same classifier, trained on Mika's data and tested on Daniel's data\n",
    "\n",
    "Done to see how data compares between people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin, end = 3, 30 # (begin is inclusive, end is exclusive)\n",
    "count_samples = {\n",
    "    \"active\": 5,\n",
    "    \"meditate\": 5,\n",
    "    \"neutral\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define `Sample` class to store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample:\n",
    "    def __init__(self):\n",
    "        self.data = {\n",
    "            'RawEEG': [],\n",
    "            'Alpha': [],\n",
    "            'Low Beta': [],\n",
    "            'High Beta': [],\n",
    "            'Gamma': [],\n",
    "            'Theta': [],\n",
    "            'Delta': [],\n",
    "            'Meditation': [],\n",
    "            'Attention': []\n",
    "        }\n",
    "\n",
    "    def recordDataPoint(self, RawEEG, Attention, Meditation, Alpha, Delta, Theta, LowBeta, HighBeta, Gamma):\n",
    "        self.data['RawEEG'].append(float(RawEEG))\n",
    "        self.data['Attention'].append(float(Attention))\n",
    "        self.data['Meditation'].append(float(Meditation))\n",
    "        self.data['Alpha'].append(float(Alpha))\n",
    "        self.data['Delta'].append(float(Delta))\n",
    "        self.data['Theta'].append(float(Theta))\n",
    "        self.data['Low Beta'].append(float(LowBeta))\n",
    "        self.data['High Beta'].append(float(HighBeta))\n",
    "        self.data['Gamma'].append(float(Gamma))\n",
    "\n",
    "    '''\n",
    "    Record a line of data from the CSV output, which takes form RawEEG, Alpha, Delta, Gamma, Low Beta, High Beta, Theta, Attention, Meditation\n",
    "\n",
    "    '''\n",
    "    def recordDataLine(self, line):\n",
    "        self.recordDataPoint(line[0], line[7], line[8], line[1], line[2], line[6], line[4], line[5], line[3])\n",
    "    \n",
    "    def getEEG(self):\n",
    "        return self.data['RawEEG']\n",
    "    \n",
    "    def getAttention(self):\n",
    "        return self.data[\"Attention\"]\n",
    "    \n",
    "    def getMeditation(self):\n",
    "        return self.data[\"Meditation\"]\n",
    "    \n",
    "    def getAlpha(self):\n",
    "        return self.data[\"Alpha\"]\n",
    "    \n",
    "    def getDelta(self):\n",
    "        return self.data[\"Delta\"]\n",
    "    \n",
    "    def getTheta(self):\n",
    "        return self.data[\"Theta\"]\n",
    "    \n",
    "    def getLowBeta(self):\n",
    "        return self.data[\"Low Beta\"]\n",
    "    \n",
    "    def getHighBeta(self):\n",
    "        return self.data[\"High Beta\"]\n",
    "    \n",
    "    def getGamma(self):\n",
    "        return self.data[\"Gamma\"]\n",
    "\n",
    "    def get(self, key):\n",
    "        return self.data[key]\n",
    "\n",
    "    '''\n",
    "    Scales the data by standard deviation of the EEG data\n",
    "    '''\n",
    "    def scale(self):\n",
    "        eeg_std_dev = np.std(self.data['RawEEG'])\n",
    "        self.data['Alpha'] = [x / eeg_std_dev for x in self.data['Alpha']]\n",
    "        self.data['Delta'] = [x / eeg_std_dev for x in self.data['Delta']]\n",
    "        self.data['Theta'] = [x / eeg_std_dev for x in self.data['Theta']]\n",
    "        self.data['Low Beta'] = [x / eeg_std_dev for x in self.data['Low Beta']]\n",
    "        self.data['High Beta'] = [x / eeg_std_dev for x in self.data['High Beta']]\n",
    "        self.data['Gamma'] = [x / eeg_std_dev for x in self.data['Gamma']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribe from file to samples stored in the `data` and `dataLabels` lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "dataLabels = []\n",
    "\n",
    "def transcribeFileToSample(sampleN: int, state: str):\n",
    "    sample_data = Sample()\n",
    "\n",
    "    with open(\"raw_cv_data/\" + state + str(sampleN) + \".csv\") as f:\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "        header = next(reader)\n",
    "        \n",
    "        for row in reader:\n",
    "            sample_data.recordDataLine(row)\n",
    "\n",
    "        for key in sample_data.data:\n",
    "            sample_data.data[key] = sample_data.data[key][begin:end]\n",
    "\n",
    "        sample_data.scale()\n",
    "\n",
    "        data.append(sample_data)\n",
    "        dataLabels.append(state)\n",
    "\n",
    "for state in count_samples:\n",
    "    for i in range(count_samples[state]):\n",
    "        transcribeFileToSample(i + 1, state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features from raw data and store in `dataExtracted`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataExtracted = []\n",
    "\n",
    "for point in data:\n",
    "    extractedPoint = []\n",
    "\n",
    "    extractedPoint.append(np.mean(point.getAlpha()))\n",
    "    extractedPoint.append(np.mean(point.getLowBeta()))\n",
    "    extractedPoint.append(np.std(point.getAlpha()))\n",
    "    extractedPoint.append(np.mean(point.getTheta()))\n",
    "    extractedPoint.append(np.std(point.getGamma()))\n",
    "    extractedPoint.append(np.std(point.getDelta()))\n",
    "\n",
    "    dataExtracted.append(extractedPoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split and train different classifiers - average over many trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5829999999999996\n",
      "{'active': {'neutral': 358, 'meditate': 110}, 'neutral': {'active': 578, 'meditate': 67}, 'meditate': {'active': 134, 'neutral': 4}}\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), LinearDiscriminantAnalysis(n_components=1))\n",
    "clf.fit(dataExtracted, dataLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_begin = 5\n",
    "cv_end = 61\n",
    "\n",
    "cv_data = []\n",
    "cv_dataLabels = []\n",
    "\n",
    "cv_samples = {\n",
    "    \"active\": 15,\n",
    "    \"neutral\": 15,\n",
    "    \"meditate\": 15\n",
    "}\n",
    "\n",
    "def cv_transcribeFileToSample(sampleN: int, state: str):\n",
    "    sample_data = Sample()\n",
    "\n",
    "    with open(\"raw_data/\" + state + str(sampleN) + \".csv\") as f:\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "        header = next(reader)\n",
    "        \n",
    "        for row in reader:\n",
    "            sample_data.recordDataLine(row)\n",
    "\n",
    "        for key in sample_data.data:\n",
    "            sample_data.data[key] = sample_data.data[key][cv_begin:cv_end]\n",
    "\n",
    "        sample_data.scale()\n",
    "\n",
    "        cv_data.append(sample_data)\n",
    "        cv_dataLabels.append(state)\n",
    "\n",
    "for state in cv_samples:\n",
    "    for i in range(cv_samples[state]):\n",
    "        cv_transcribeFileToSample(i + 1, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_extracted = []\n",
    "\n",
    "for point in cv_data:\n",
    "    extractedPoint = []\n",
    "\n",
    "    extractedPoint.append(np.mean(point.getAlpha()))\n",
    "    extractedPoint.append(np.mean(point.getLowBeta()))\n",
    "    extractedPoint.append(np.std(point.getAlpha()))\n",
    "    extractedPoint.append(np.mean(point.getTheta()))\n",
    "    extractedPoint.append(np.std(point.getGamma()))\n",
    "    extractedPoint.append(np.std(point.getDelta()))\n",
    "\n",
    "    cv_extracted.append(extractedPoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  ['neutral' 'neutral' 'neutral' 'neutral' 'neutral' 'neutral' 'neutral'\n",
      " 'neutral' 'meditate' 'neutral' 'neutral' 'neutral' 'neutral' 'neutral'\n",
      " 'neutral' 'neutral' 'neutral' 'neutral' 'neutral' 'neutral' 'neutral'\n",
      " 'neutral' 'neutral' 'neutral' 'neutral' 'neutral' 'neutral' 'active'\n",
      " 'neutral' 'neutral' 'meditate' 'meditate' 'neutral' 'neutral' 'meditate'\n",
      " 'meditate' 'meditate' 'meditate' 'meditate' 'meditate' 'meditate'\n",
      " 'meditate' 'meditate' 'meditate' 'meditate']\n",
      "Real Labels:  ['active', 'active', 'active', 'active', 'active', 'active', 'active', 'active', 'active', 'active', 'active', 'active', 'active', 'active', 'active', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'meditate', 'meditate', 'meditate', 'meditate', 'meditate', 'meditate', 'meditate', 'meditate', 'meditate', 'meditate', 'meditate', 'meditate', 'meditate', 'meditate', 'meditate']\n",
      "Correct 60.0% of the time!\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(cv_extracted)\n",
    "\n",
    "print(\"Predictions: \", predictions)\n",
    "print(\"Real Labels: \", cv_dataLabels)\n",
    "print(\"Correct \" + str(100*clf.score(cv_extracted, cv_dataLabels)) + \"% of the time!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['active'], dtype='<U8')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = Sample()\n",
    "\n",
    "with open(\"active_lang_mcq.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "\n",
    "    header = next(reader)\n",
    "    \n",
    "    for row in reader:\n",
    "        sample_data.recordDataLine(row)\n",
    "\n",
    "    for key in sample_data.data:\n",
    "        sample_data.data[key] = sample_data.data[key][5:58]\n",
    "\n",
    "    sample_data.scale()\n",
    "\n",
    "extractedPoint = []\n",
    "\n",
    "extractedPoint.append(np.mean(sample_data.getAlpha()))\n",
    "extractedPoint.append(np.mean(sample_data.getLowBeta()))\n",
    "extractedPoint.append(np.std(sample_data.getAlpha()))\n",
    "extractedPoint.append(np.mean(sample_data.getTheta()))\n",
    "extractedPoint.append(np.std(sample_data.getGamma()))\n",
    "extractedPoint.append(np.std(sample_data.getDelta()))\n",
    "\n",
    "pred = clf.predict(np.array(extractedPoint).reshape(1, -1))\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
  },
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
